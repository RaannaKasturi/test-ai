llama-cpp-python -C cmake.args="-DGGML_BLAS=ON;-DGGML_BLAS_VENDOR=OpenBLAS"
pillow
pymupdf
accelerate
langchain-community
langchain-huggingface
faiss-cpu
openvino-dev
optimum[openvino]
transformers
sentence-transformers
torch --index-url https://download.pytorch.org/whl/cpu
torchvision --index-url https://download.pytorch.org/whl/cpu
torchaudio --index-url https://download.pytorch.org/whl/cpu
